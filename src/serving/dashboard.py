
import sys
import os

# --- [B·∫ÆT BU·ªòC] ƒêO·∫†N CODE N√ÄY PH·∫¢I N·∫∞M TR√äN C√ôNG ---
# Gi√∫p Python t√¨m th·∫•y th∆∞ m·ª•c g·ªëc 'smb_data_hub'
current_dir = os.path.dirname(os.path.abspath(__file__))
# ƒêi ng∆∞·ª£c l√™n 2 c·∫•p th∆∞ m·ª•c: src/serving -> src -> smb_data_hub
project_root = os.path.abspath(os.path.join(current_dir, '..', '..'))
if project_root not in sys.path:
    sys.path.append(project_root)
# ---------------------------------------------------

# SAU ƒê√ì M·ªöI ƒê∆Ø·ª¢C IMPORT C√ÅC MODULE KH√ÅC
import streamlit as st
import pandas as pd
import yaml
import time
from sqlalchemy import create_engine, text
from src.storage.db_handler import DBHandler
# Import c√°c module t·ª± vi·∫øt
try:
    from src.serving.chatbot import Chatbot
    from src.ingestion.file_uploader import save_uploaded_file
except ModuleNotFoundError as e:
    st.error(f"L·ªói kh√¥ng t√¨m th·∫•y module: {e}")
    st.info("H√£y ki·ªÉm tra xem b·∫°n ƒë√£ t·∫°o file '__init__.py' trong c√°c th∆∞ m·ª•c src, src/ingestion ch∆∞a?")
    st.stop()

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="SMB Data Hub", layout="wide", page_icon="üè¢")

# Load Config
config_path = os.path.join(project_root, "config", "settings.yaml")
if not os.path.exists(config_path):
    st.error(f"Kh√¥ng t√¨m th·∫•y file config t·∫°i: {config_path}")
    st.stop()

with open(config_path, "r") as f:
    config = yaml.safe_load(f)

# Kh·ªüi t·∫°o DBHandler ƒë·ªÉ n√≥ t·ª± ƒë·ªông ch·∫°y l·ªánh CREATE TABLE n·∫øu ch∆∞a c√≥
try:
    DBHandler(config['database']['connection_string'])
except Exception as e:
    st.error(f"L·ªói kh·ªüi t·∫°o Database: {e}")
# -----------------------

# K·∫øt n·ªëi DB & Chatbot
db_url = config['database']['connection_string']
engine = create_engine(db_url)
bot = Chatbot(db_url)

# --- SIDEBAR: UPLOAD & SETTINGS ---
with st.sidebar:
    st.title("üìÇ Data Ingestion")
    st.info("Upload file Excel/CSV ƒë·ªÉ ch·∫°y pipeline t·ª± ƒë·ªông.")
    
    uploaded_file = st.file_uploader("Ch·ªçn file d·ªØ li·ªáu", type=['csv', 'xlsx'])
    
    if uploaded_file is not None:
        if st.button("üöÄ Upload & Process"):
            # 1. Upload file
            with st.spinner("ƒêang t·∫£i file l√™n h·ªá th·ªëng..."):
                upload_dir = os.path.join(project_root, config['data_dirs']['upload'])
                success, msg = save_uploaded_file(uploaded_file, upload_dir)
            
            if success:
                # 2. T·∫°o h·ªôp th√¥ng b√°o tr·∫°ng th√°i ch·ªù
                status_box = st.info(f"‚è≥ File `{uploaded_file.name}` ƒë√£ v√†o h√†ng ƒë·ª£i. ƒêang ch·ªù x·ª≠ l√Ω...")
                progress_bar = st.progress(0)
                
                # 3. V√≤ng l·∫∑p ki·ªÉm tra (Polling) xem xong ch∆∞a
                # Th·ª≠ t·ªëi ƒëa 20 l·∫ßn, m·ªói l·∫ßn ƒë·ª£i 1 gi√¢y (T·ªïng 20s)
                max_retries = 20
                is_processed = False
                
                for i in range(max_retries):
                    time.sleep(1) # ƒê·ª£i 1 gi√¢y
                    progress_bar.progress((i + 1) / max_retries)
                    
                    # Truy v·∫•n th·ª≠ v√†o Database xem file n√†y ƒë√£ xu·∫•t hi·ªán trong b·∫£ng logs ch∆∞a
                    try:
                        # Query t√¨m file m·ªõi nh·∫•t c√≥ t√™n tr√πng kh·ªõp
                        check_query = f"SELECT status FROM process_logs WHERE file_name = '{uploaded_file.name}' ORDER BY upload_time DESC LIMIT 1"
                        df_check = pd.read_sql(check_query, engine)
                        
                        if not df_check.empty:
                            # N·∫øu t√¨m th·∫•y d·ªØ li·ªáu -> Nghƒ©a l√† Pipeline ƒë√£ ch·∫°y xong!
                            is_processed = True
                            break
                    except Exception:
                        pass # B·ªè qua l·ªói k·∫øt n·ªëi t·∫°m th·ªùi n·∫øu c√≥
                
                # 4. X·ª≠ l√Ω k·∫øt qu·∫£
                if is_processed:
                    progress_bar.progress(100)
                    status_box.success("‚úÖ ƒê√£ x·ª≠ l√Ω xong! ƒêang c·∫≠p nh·∫≠t Dashboard...")
                    time.sleep(1) # ƒê·ªÉ ng∆∞·ªùi d√πng k·ªãp ƒë·ªçc th√¥ng b√°o
                    st.rerun() # T·ª± ƒë·ªông F5
                else:
                    status_box.warning("‚ö†Ô∏è File l·ªõn ho·∫∑c h·ªá th·ªëng b·∫≠n. Vui l√≤ng F5 th·ªß c√¥ng sau v√†i gi√¢y.")
            else:
                st.error(f"L·ªói upload: {msg}")

    st.divider()
    # --- [TH√äM ƒêO·∫†N N√ÄY V√ÄO CU·ªêI SIDEBAR] ---
    st.subheader("‚ö†Ô∏è Qu·∫£n tr·ªã")
    if st.button("üóëÔ∏è Reset To√†n B·ªô H·ªá Th·ªëng"):
        with st.spinner("ƒêang l√†m s·∫°ch h·ªá th·ªëng..."):
            import shutil
            
            # 1. X√≥a d·ªØ li·ªáu trong Database
            try:
                with engine.connect() as conn:
                    conn.execute(text("DELETE FROM process_logs"))
                    try:
                        conn.execute(text("DELETE FROM customers_telco"))
                    except:
                        pass
                    
                    # Reset b·ªô ƒë·∫øm ID (cho SQLite)
                    try:
                        conn.execute(text("DELETE FROM sqlite_sequence WHERE name='process_logs'"))
                    except:
                        pass
                        
                    conn.commit()
            except Exception as e:
                st.error(f"L·ªói khi x√≥a DB: {e}")
            
            # 2. X√≥a file trong c√°c th∆∞ m·ª•c
            folders_to_clean = [
                os.path.join(project_root, "data", "raw"),
                os.path.join(project_root, "data", "clean"),
                os.path.join(project_root, "data", "error"),
                os.path.join(project_root, "data", "uploads"),
                os.path.join(project_root, "logs")
            ]
            
            for folder_path in folders_to_clean:
                if os.path.exists(folder_path):
                    for filename in os.listdir(folder_path):
                        file_path = os.path.join(folder_path, filename)
                        try:
                            if os.path.isfile(file_path) or os.path.islink(file_path):
                                os.unlink(file_path)
                            elif os.path.isdir(file_path):
                                shutil.rmtree(file_path)
                        except Exception as e:
                            print(f"Kh√¥ng x√≥a ƒë∆∞·ª£c {file_path}: {e}")

            # [QUAN TR·ªåNG] 3. X√≥a s·∫°ch Session State (B·ªô nh·ªõ t·∫°m)
            # B∆∞·ªõc n√†y gi√∫p x√≥a l·ªãch s·ª≠ chat v√† c√°c bi·∫øn ƒë√£ l∆∞u
            st.session_state.clear()

            st.success("ƒê√£ l√†m s·∫°ch d·ªØ li·ªáu th√†nh c√¥ng!")
            time.sleep(1)
            
            # 4. T·ª± ƒë·ªông Rerun (F5)
            st.rerun()

    st.caption(f"Phi√™n b·∫£n: 1.0.0 | Environment: {os.name}")

# --- MAIN DASHBOARD ---
st.title("üìä SMB Data Hub - Monitor Center")

# TAB SYSTEM
tab1, tab2, tab3 = st.tabs(["üìà Dashboard T·ªïng Quan", "ü§ñ Tr·ª£ L√Ω D·ªØ Li·ªáu", "üìú Logs Chi Ti·∫øt"])

with tab1:
    st.header("Tr·∫°ng th√°i s·ª©c kh·ªèe h·ªá th·ªëng")
    try:
        logs = pd.read_sql("SELECT * FROM process_logs", engine)
        
        if not logs.empty:
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("File ƒê√£ X·ª≠ L√Ω", len(logs))
            
            valid_sum = logs['valid_rows'].sum() if 'valid_rows' in logs else 0
            total_sum = logs['total_rows'].sum() if 'total_rows' in logs else 1 # Tr√°nh chia cho 0
            
            clean_rate = round((valid_sum / total_sum) * 100, 1)
            col2.metric("T·ª∑ l·ªá S·∫°ch", f"{clean_rate}%")
            col3.metric("T·ªïng D√≤ng L·ªói", logs['error_rows'].sum())
            
            last_run = pd.to_datetime(logs['upload_time']).iloc[-1].strftime('%H:%M')
            col4.metric("Last Run", last_run)
            
            st.subheader("Bi·ªÉu ƒë·ªì ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu")
            if 'file_name' in logs.columns:
                chart_data = logs[['file_name', 'valid_rows', 'error_rows']].tail(10)
                st.bar_chart(chart_data.set_index('file_name'))
        else:
            st.info("H·ªá th·ªëng ch∆∞a c√≥ d·ªØ li·ªáu. Vui l√≤ng upload file ·ªü menu b√™n tr√°i.")
            
    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi Database ho·∫∑c ch∆∞a c√≥ b·∫£ng log: {e}")

with tab2:
    st.header("Chat v·ªõi d·ªØ li·ªáu (Demo)")
    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω Data Engineer. B·∫°n c·∫ßn ki·ªÉm tra g√¨ h√¥m nay?"}]

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if prompt := st.chat_input("VD: File v·ª´a n·∫°p c√≥ l·ªói kh√¥ng?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ƒêang truy v·∫•n metadata..."):
                response = bot.process_query(prompt)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

with tab3:
    st.header("Audit Trail & Data Lineage")
    try:
        logs_df = pd.read_sql("SELECT * FROM process_logs ORDER BY upload_time DESC", engine)
        st.dataframe(logs_df, use_container_width=True)
    except:
        st.caption("Ch∆∞a c√≥ logs.")